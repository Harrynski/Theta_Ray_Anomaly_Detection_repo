{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import LocalOutlierFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "og_data = pd.read_excel(rf'Files/TXS que el collector no ve NOV23 al final del mes.xlsx')\n",
    "og_data = og_data.rename(columns={'Id_x':'Id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "og_data = og_data.astype({'TransactionId':'str', 'SenderPhoneNumber':'str' })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NicolasSilvaNash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df = og_data.copy()\n",
    "df = df.set_index('CreatedAt')\n",
    "\n",
    "X = pd.get_dummies(df[['Client', 'VendorCode', \n",
    "       'CollectMethod', 'TargetCountry',  'NetAmountUSD',\n",
    "       'SourceCountry']])\n",
    "\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "IF = IsolationForest(random_state=0, contamination=0.1).fit(X)\n",
    "\n",
    "df['Anomaly_scores']  = IF.decision_function(X)\n",
    "df['is_anomaly']  = IF.predict(X)\n",
    "df.sort_values(by='is_anomaly')\n",
    "anomalias = df[df.is_anomaly==-1].sort_values(by='Anomaly_scores', ascending=True)\n",
    "\n",
    "df.to_excel(rf'IF anomalies - NOV 23.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSFT GUIDE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "og_data = og_data[og_data.Status=='COMPLETED']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "og_data = og_data[['CreatedAt', 'Id', 'TransactionId', 'Client', 'VendorCode', 'TargetCountry', 'TargetCurrency', 'NetAmountUSD',\n",
    "       'SourceCountry', 'SenderFirstName',\n",
    "       'SenderLastName', 'SenderDocument', 'SenderPhoneNumber',\n",
    "       'senderCountry', 'receiverFirstName', 'receiverLastName',\n",
    "       'receiverDocument', 'receiverDocumentType', 'receiverPhoneNumber',\n",
    "       'receiverCountry', 'receiverBankAccountNumber',\n",
    "       'receiverBankAccountType']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zscore(value, mean, std):\n",
    "    # calculate z-score or number of standard deviations from mean\n",
    "    if (\n",
    "        std == 0\n",
    "        or std is None\n",
    "        or str(std).lower() in [\"nan\", \"none\", \"null\"]\n",
    "        or mean is None\n",
    "    ):\n",
    "        if value == 0.0:\n",
    "            return 0.0\n",
    "        elif value != 0:\n",
    "            return value #np.log10(value + 1)\n",
    "    ans = (value - mean) / std\n",
    "    # only interested in increases\n",
    "    #ans = max(0.0, ans)\n",
    "    # take log to dampen numbers\n",
    "    #ans = np.log10(ans + 1)\n",
    "    return float(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = og_data.copy()\n",
    "data['Date'] = data.CreatedAt.dt.date\n",
    "zscore_columns = [\n",
    "    \"NetAmountUSD\"\n",
    "]\n",
    "\n",
    "#usamos documento del enviador y phone number del recibidor porque son los que mas hay\n",
    "ind = ['Date', 'Client', 'VendorCode', 'SourceCountry', 'TargetCountry', 'TargetCurrency', \n",
    "    'SenderDocument', 'receiverPhoneNumber', 'receiverBankAccountNumber']\n",
    "\n",
    "means = [x + \"_\" + y + \"_mean\" for x in zscore_columns for y in ind]\n",
    "stds = [x + \"_\" + y + \"_std\" for x in zscore_columns for y in ind]\n",
    "zscores = [x + \"_\" + y + \"_zscore\" for x in zscore_columns for y in ind]\n",
    "\n",
    "zscore = data[zscore_columns + ind]\n",
    "zscore = zscore.fillna(0)\n",
    "\n",
    "\n",
    "for metric, index in zip(means,ind):\n",
    "    zscore[metric] = zscore.groupby([index])[zscore_columns].transform(\"mean\")\n",
    "\n",
    "for metric, index in zip(stds,ind):\n",
    "    zscore[metric] = zscore.groupby([index])[zscore_columns].transform(\"std\", ddof=1)\n",
    "\n",
    "\n",
    "zscore = zscore.drop_duplicates(ind)\n",
    "zscore = zscore[means + stds + ind]\n",
    "data = data.merge(zscore, how=\"left\", on=ind)\n",
    "\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "for column,feature in product(zscore_columns, ind):\n",
    "    data[f\"{column}_{feature}_zscore\"] = data.apply(\n",
    "        lambda row: get_zscore(\n",
    "            row[f\"{column}\"], row[f\"{column}_{feature}_mean\"], row[f\"{column}_{feature}_std\"]\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counts by sender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "sender_count_columns=['Id', 'Date', 'Client', 'VendorCode', 'TargetCountry', 'TargetCurrency',  'receiverPhoneNumber', 'receiverBankAccountNumber']\n",
    "sender_count_ind = ['SenderDocument']\n",
    "\n",
    "sender_counts = [\"Sender_\" + x + \"_count\" for x in sender_count_columns]\n",
    "\n",
    "sender_count = data[sender_count_columns + sender_count_ind]\n",
    "sender_count = sender_count.fillna(0)\n",
    "\n",
    "for column  in sender_count_columns:\n",
    "    #print(column)\n",
    "    sender_count[f\"Sender_{column}_count\"] = sender_count.groupby('SenderDocument')[column].transform(\"nunique\")\n",
    "\n",
    "sender_count = sender_count.drop_duplicates(sender_count_ind)\n",
    "sender_count = sender_count[sender_counts + sender_count_ind]\n",
    "\n",
    "for att in sender_counts:\n",
    "    if (sender_count[att].max()==1):\n",
    "        sender_count.drop(columns={att}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.merge(sender_count, how=\"left\", on=sender_count_ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counts by receiver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "receiver_count_columns=['Id', 'Date', 'Client', 'VendorCode', 'SourceCountry', 'SenderDocument']\n",
    "receiver_count_ind = ['receiverPhoneNumber']\n",
    "\n",
    "receiver_counts = [\"receiver_\" + x + \"_count\" for x in receiver_count_columns]\n",
    "\n",
    "receiver_count = data[receiver_count_columns + receiver_count_ind]\n",
    "receiver_count = receiver_count.fillna(0)\n",
    "\n",
    "for column  in receiver_count_columns:\n",
    "    #print(column)\n",
    "    receiver_count[f\"receiver_{column}_count\"] = receiver_count.groupby('receiverPhoneNumber')[column].transform(\"nunique\")\n",
    "\n",
    "receiver_count = receiver_count.drop_duplicates(receiver_count_ind)\n",
    "receiver_count = receiver_count[receiver_counts + receiver_count_ind]\n",
    "\n",
    "for att in receiver_counts:\n",
    "    if (receiver_count[att].max()==1):\n",
    "        receiver_count.drop(columns={att}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.merge(receiver_count, how=\"left\", on=receiver_count_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CreatedAt', 'Id', 'TransactionId', 'Client', 'VendorCode',\n",
       "       'TargetCountry', 'TargetCurrency', 'NetAmountUSD', 'SourceCountry',\n",
       "       'SenderFirstName', 'SenderLastName', 'SenderDocument',\n",
       "       'SenderPhoneNumber', 'senderCountry', 'receiverFirstName',\n",
       "       'receiverLastName', 'receiverDocument', 'receiverDocumentType',\n",
       "       'receiverPhoneNumber', 'receiverCountry', 'receiverBankAccountNumber',\n",
       "       'receiverBankAccountType', 'Date', 'NetAmountUSD_Date_mean',\n",
       "       'NetAmountUSD_Client_mean', 'NetAmountUSD_VendorCode_mean',\n",
       "       'NetAmountUSD_SourceCountry_mean', 'NetAmountUSD_TargetCountry_mean',\n",
       "       'NetAmountUSD_TargetCurrency_mean', 'NetAmountUSD_SenderDocument_mean',\n",
       "       'NetAmountUSD_receiverPhoneNumber_mean',\n",
       "       'NetAmountUSD_receiverBankAccountNumber_mean', 'NetAmountUSD_Date_std',\n",
       "       'NetAmountUSD_Client_std', 'NetAmountUSD_VendorCode_std',\n",
       "       'NetAmountUSD_SourceCountry_std', 'NetAmountUSD_TargetCountry_std',\n",
       "       'NetAmountUSD_TargetCurrency_std', 'NetAmountUSD_SenderDocument_std',\n",
       "       'NetAmountUSD_receiverPhoneNumber_std',\n",
       "       'NetAmountUSD_receiverBankAccountNumber_std',\n",
       "       'NetAmountUSD_Date_zscore', 'NetAmountUSD_Client_zscore',\n",
       "       'NetAmountUSD_VendorCode_zscore', 'NetAmountUSD_SourceCountry_zscore',\n",
       "       'NetAmountUSD_TargetCountry_zscore',\n",
       "       'NetAmountUSD_TargetCurrency_zscore',\n",
       "       'NetAmountUSD_SenderDocument_zscore',\n",
       "       'NetAmountUSD_receiverPhoneNumber_zscore',\n",
       "       'NetAmountUSD_receiverBankAccountNumber_zscore', 'Sender_Id_count',\n",
       "       'Sender_Date_count', 'Sender_VendorCode_count',\n",
       "       'Sender_receiverPhoneNumber_count',\n",
       "       'Sender_receiverBankAccountNumber_count', 'receiver_Id_count',\n",
       "       'receiver_Date_count', 'receiver_VendorCode_count',\n",
       "       'receiver_SenderDocument_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Isolation Forest application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_isolation_forest(df, n_estimators, contamination=0.01):\n",
    "    \"\"\"Applies Isolation Forest to a given dataset and returns the predicted anomalies.\"\"\"\n",
    "    clf = IsolationForest(\n",
    "        n_estimators=n_estimators,\n",
    "        max_samples=\"auto\",\n",
    "        contamination=contamination,\n",
    "        max_features=6,\n",
    "        bootstrap=False,\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        verbose=0,\n",
    "    )\n",
    "    clf.fit(df.values)\n",
    "    pred = clf.predict(df.values)\n",
    "    scores = clf.decision_function(df.values)\n",
    "    return clf, pred, scores\n",
    "\n",
    "# specify the metrics column names to be modelled\n",
    "features = [\n",
    "        'Client', 'VendorCode',\n",
    "       'TargetCountry', 'TargetCurrency', 'NetAmountUSD', 'SourceCountry',\n",
    "       'NetAmountUSD_Date_mean',\n",
    "       'NetAmountUSD_Client_mean', 'NetAmountUSD_VendorCode_mean',\n",
    "       'NetAmountUSD_SourceCountry_mean', 'NetAmountUSD_TargetCountry_mean',\n",
    "       'NetAmountUSD_TargetCurrency_mean', 'NetAmountUSD_SenderDocument_mean',\n",
    "       'NetAmountUSD_receiverPhoneNumber_mean',\n",
    "       'NetAmountUSD_receiverBankAccountNumber_mean', 'NetAmountUSD_Date_std',\n",
    "       'NetAmountUSD_Client_std', 'NetAmountUSD_VendorCode_std',\n",
    "       'NetAmountUSD_SourceCountry_std', 'NetAmountUSD_TargetCountry_std',\n",
    "       'NetAmountUSD_TargetCurrency_std', 'NetAmountUSD_SenderDocument_std',\n",
    "       'NetAmountUSD_receiverPhoneNumber_std',\n",
    "       'NetAmountUSD_receiverBankAccountNumber_std',\n",
    "       'NetAmountUSD_Date_zscore', 'NetAmountUSD_Client_zscore',\n",
    "       'NetAmountUSD_VendorCode_zscore', 'NetAmountUSD_SourceCountry_zscore',\n",
    "       'NetAmountUSD_TargetCountry_zscore',\n",
    "       'NetAmountUSD_TargetCurrency_zscore',\n",
    "       'NetAmountUSD_SenderDocument_zscore',\n",
    "       'NetAmountUSD_receiverPhoneNumber_zscore',\n",
    "       'NetAmountUSD_receiverBankAccountNumber_zscore', 'Sender_Id_count',\n",
    "       'Sender_Date_count', 'Sender_VendorCode_count',\n",
    "       'Sender_receiverPhoneNumber_count',\n",
    "       'Sender_receiverBankAccountNumber_count', 'receiver_Id_count',\n",
    "       'receiver_Date_count', 'receiver_VendorCode_count',\n",
    "       'receiver_SenderDocument_count'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trees 100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'SANTANDERCHL'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[378], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# n_estimators = 100\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of trees\u001b[39m\u001b[38;5;124m\"\u001b[39m, n_estimators)\n\u001b[1;32m---> 12\u001b[0m clf, pred, scores \u001b[38;5;241m=\u001b[39m \u001b[43mapply_isolation_forest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontamination\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manomaly\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m pred\n\u001b[0;32m     14\u001b[0m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m scores \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[1;32mIn[377], line 13\u001b[0m, in \u001b[0;36mapply_isolation_forest\u001b[1;34m(df, n_estimators, contamination)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Applies Isolation Forest to a given dataset and returns the predicted anomalies.\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m clf \u001b[38;5;241m=\u001b[39m IsolationForest(\n\u001b[0;32m      4\u001b[0m     n_estimators\u001b[38;5;241m=\u001b[39mn_estimators,\n\u001b[0;32m      5\u001b[0m     max_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m     12\u001b[0m )\n\u001b[1;32m---> 13\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m pred \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(df\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[0;32m     15\u001b[0m scores \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mdecision_function(df\u001b[38;5;241m.\u001b[39mvalues)\n",
      "File \u001b[1;32mc:\\Users\\NicolasSilvaNash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_iforest.py:290\u001b[0m, in \u001b[0;36mIsolationForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;124;03mFit estimator.\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;124;03m    Fitted estimator.\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m--> 290\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtree_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n\u001b[0;32m    292\u001b[0m     \u001b[38;5;66;03m# Pre-sort indices to avoid that each individual tree of the\u001b[39;00m\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;66;03m# ensemble sorts the indices.\u001b[39;00m\n\u001b[0;32m    294\u001b[0m     X\u001b[38;5;241m.\u001b[39msort_indices()\n",
      "File \u001b[1;32mc:\\Users\\NicolasSilvaNash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    563\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 565\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    566\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32mc:\\Users\\NicolasSilvaNash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    877\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    878\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 879\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    882\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    883\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\NicolasSilvaNash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    182\u001b[0m     xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(array)\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xp\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy.array_api\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39masarray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'SANTANDERCHL'"
     ]
    }
   ],
   "source": [
    "X = data[features].copy()\n",
    "X = X.fillna(0)\n",
    "\n",
    "if X.shape[0] < 500:\n",
    "    n_estimators = len(features) * 4 + X.shape[0] * 2\n",
    "else:\n",
    "    n_estimators = 100\n",
    "\n",
    "# n_estimators = 100\n",
    "print(\"Number of trees\", n_estimators)\n",
    "\n",
    "clf, pred, scores = apply_isolation_forest(X, n_estimators, contamination=0.01)\n",
    "data[\"anomaly\"] = pred\n",
    "data[\"score\"] = scores * -1\n",
    "# excluding users who do not have any successful logon history.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc[data[\"SuccessfulLogons\"] > 0]\n",
    "outliers = data.loc[data[\"anomaly\"] == -1]\n",
    "outlier_index = list(outliers.index)\n",
    "print(f\"Outliers at indexes: {outlier_index}\")\n",
    "# Find the number of anomalies and normal points here points classified -1 are anomalous\n",
    "print(data[\"anomaly\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
